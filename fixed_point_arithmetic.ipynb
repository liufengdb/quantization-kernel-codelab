{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import math\n",
    "\n",
    "from quantization import Tensor\n",
    "from quantization_utils import *\n",
    "from data_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Point\n",
    "\n",
    "---\n",
    "## What's Fixed Point?\n",
    "\n",
    "You may refer [here](https://stackoverflow.com/questions/7524838/fixed-point-vs-floating-point-number) for the difference between fixed point & floating point.\n",
    "\n",
    "We usually use [Qm.n notation](https://en.wikipedia.org/wiki/Q_%28number_format%29) to represent the fixed point.\n",
    "\n",
    "For example Q3.12 means we use 3 bits to represent the integer parts and 12 bits to represent the fractional parts (and one bit to sign).\n",
    "\n",
    "So the range for Qm.n is [-2^m, 2^(m+1) - 2^-n]\n",
    "\n",
    "---\n",
    "## Fixed Point <-> Floating point?\n",
    "\n",
    "In this case, we will represent all the fixed point using integer values (int16, int32, etc.), and the floating value is simply:\n",
    "\n",
    "$$value_{float} = value_{int} * 2^{-frac_{bits}}$$\n",
    "\n",
    "where $$frac_{bits} = total_{bits} - integer_{bits} - 1$$\n",
    "\n",
    "So convert floating point value x to Qm.n format is simply:\n",
    "\n",
    "$$value_{int} = value_{float} * 2^{n}$$\n",
    "\n",
    "---\n",
    "## Why Fixed Point matters?\n",
    "\n",
    "Fixed point arithmetics can be very useful for division, tanh, exp and others.\n",
    "\n",
    "This codelab will focus on division mainly with brief introduction to others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fixed Point Arithmetic\n",
    "\n",
    "Let's just focus on Qm.n case first. It's easier to convert Qm.n into Qm1.n1 case (where just bits shifting).\n",
    "\n",
    "---\n",
    "## Add\n",
    "\n",
    "So we have\n",
    "\n",
    "$$lhs_{float} = lhs_{int} * 2^{-n}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$rhs_{float} = rhs_{int} * 2^{-n}$$\n",
    "\n",
    "Our desired output is:\n",
    "\n",
    "$$out_{int} = (lhs_{float} + rhs_{float}) * 2^{n}$$\n",
    "\n",
    "=>\n",
    "\n",
    "$$out_{int} = (lhs_{int} * 2^{-n} + rhs_{int} * 2^{-n}) * 2^{n}$$\n",
    "\n",
    "=>\n",
    "\n",
    "$$out_{int} = (lhs_{int} + rhs_{int}) * 2^{-n} * 2^{n}$$\n",
    "\n",
    "=>\n",
    "\n",
    "$$out_{int} = lhs_{int} + rhs_{int}$$\n",
    "\n",
    "So, the output is simply the add of the int value of lhs and rhs, exactly like the int math! Very simple, right?\n",
    "\n",
    "---\n",
    "## Sub\n",
    "\n",
    "Sub is actually very similar to add, so we can just skip the deduction part :)\n",
    "\n",
    "We will have\n",
    "\n",
    "$$out_{int} = lhs_{int} - rhs_{int}$$\n",
    "\n",
    "for the sub.\n",
    "\n",
    "---\n",
    "## Mul\n",
    "\n",
    "Let's take a look at the mul:\n",
    "\n",
    "Still we have:\n",
    "\n",
    "$$lhs_{float} = lhs_{int} * 2^{-n}$$\n",
    "\n",
    "and\n",
    "\n",
    "$$rhs_{float} = rhs_{int} * 2^{-n}$$\n",
    "\n",
    "Our desired output is:\n",
    "\n",
    "$$out_{int} = (lhs_{float} * rhs_{float}) * 2^{n}$$\n",
    "\n",
    "=>\n",
    "\n",
    "$$out_{int} = (lhs_{int} * 2^{-n} * rhs_{int} * 2^{-n}) * 2^{n}$$\n",
    "\n",
    "=>\n",
    "\n",
    "$$out_{int} = (lhs_{int} * rhs_{int}) * 2^{-n} * 2^{-n} * 2^{n}$$\n",
    "\n",
    "=>\n",
    "\n",
    "$$out_{int} = (lhs_{int} * rhs_{int}) * 2^{-n}$$\n",
    "\n",
    "Given the reality that n is always >= 0, so we essentially have a normal integer mul with a right shift of n bits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Div\n",
    "\n",
    "---\n",
    "\n",
    "Div is indeed very complicated as we're limited by two constraints: 1) we're dealing with integer-only arithmetic; 2) most of the time, we don't have direct and accurate 'div' instruction available, so we really need to emulate the 'div' behavior.\n",
    "\n",
    "How are we going to do that exactly?\n",
    "\n",
    "---\n",
    "\n",
    "### Newton-Ralpson Division\n",
    "\n",
    "See the detailed reference [here](https://en.wikipedia.org/wiki/Division_algorithm#Newton.E2.80.93Raphson_division)\n",
    "\n",
    "The first observation is we can transform:\n",
    "\n",
    "$$out = lhs \\div rhs$$\n",
    "\n",
    "into $$out = lhs * (\\frac{1}{rhs})$$\n",
    "\n",
    "and for x in range of [0.5, 1], we can use the newton-ralpson method to estimate the value.\n",
    "\n",
    "Initial value is:\n",
    "\n",
    "$$x_0 = (\\frac{48}{17}) - (\\frac{32}{17}) * x$$\n",
    "\n",
    "Then we can iterate using:\n",
    "\n",
    "$$x_{new} = x_{pre} + x_{pre} * (1 - x * x_{pre})$$\n",
    "\n",
    "Normally we can get good accuracy with 2 or 3 iterations, let's just verify it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Diff for 2 iterations is 5.553048509880476e-06\n",
      "Avg Diff for 3 iterations is 4.685110077673471e-11\n",
      "Max Diff for 2 iterations is 2.394607344258226e-05\n",
      "Max Diff for 3 iterations is 2.867073245482743e-10\n"
     ]
    }
   ],
   "source": [
    "def newton_ralpson_reci(x, iteration=2):\n",
    "  a = 48.0 / 17.0\n",
    "  b = 32.0 / 17.0\n",
    "  result = a - b * x\n",
    "  for i in range(iteration):\n",
    "    result = result + result * (1 - x * result)\n",
    "  return result\n",
    "\n",
    "test_data = np.arange(0.5, 1, 0.001)\n",
    "\n",
    "expected_result = 1.0 / test_data\n",
    "\n",
    "result_iter2 = newton_ralpson_reci(test_data, 2)\n",
    "result_iter3 = newton_ralpson_reci(test_data, 3)\n",
    "\n",
    "print(\"Avg Diff for 2 iterations is %s\" % (diff(expected_result, result_iter2)))\n",
    "print(\"Avg Diff for 3 iterations is %s\" % (diff(expected_result, result_iter3)))\n",
    "print(\"Max Diff for 2 iterations is %s\" % (max_diff(expected_result, result_iter2)))\n",
    "print(\"Max Diff for 3 iterations is %s\" % (max_diff(expected_result, result_iter3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reciprocal\n",
    "---\n",
    "\n",
    "So far so good, but wait a second, isn't newton_ralpson_reci only works for [0.5, 1]? \n",
    "\n",
    "Well, we can always \"canonicalize\" the value to make it between [0.5, 1] with a proper shift by counting the leading zeros (in arm, it's just instruction 'CLS'). And yes, that only applies to positive numbers, but it should be very cheap for negative values to apply 'NEG'.\n",
    "\n",
    "---\n",
    "#### Canonicalize\n",
    "\n",
    "So for Q0.n+m case (all bits go to the fractional bits except the sign bits), we just to make sure the number of leading zeros is 1 (which is the sign bit).\n",
    "\n",
    "So we have:\n",
    "\n",
    "$$value_{FloatQ0.n+m} = value_{IntQm.n} * 2^{m} * 2^{-(m+n)}$$\n",
    "\n",
    "It's easily to get\n",
    "\n",
    "$$value_{IntQ0.n+m} = value_{IntQm.n} * 2^{m}$$\n",
    "\n",
    "In reality, simply shifting Qm.n int value left by m bits can easily result in overflow, so we don't shift it just yet, but just do that at the end.\n",
    "\n",
    "Moving forward:\n",
    "\n",
    "We know\n",
    "\n",
    "$$value_{IntCano} = value_{IntQ0.n+m} * 2^{zeros_{leading} - 1}$$\n",
    "\n",
    "so we have\n",
    "\n",
    "$$value_{FloatCano} = value_{IntQ0.n+m} * 2^{zeros_{leading} - 1} * 2^{-(zeros_{leading} - 1)} * 2^{-(m+n)}$$\n",
    "\n",
    "=>\n",
    "\n",
    "$$value_{FloatCano} = value_{IntQm.n} * 2^{m} * 2^{zeros_{leading} - 1} * 2^{-(zeros_{leading} - 1)} * 2^{-(m+n)}$$\n",
    "\n",
    "=>\n",
    "\n",
    "$$value_{FloatCano} = (value_{IntQm.n} * 2^{zeros_{leading} - 1} * 2^{-(m+n)}) * 2^{m-(zeros_{leading} - 1)}$$\n",
    "\n",
    "Let \n",
    "\n",
    "$$value_{shifted} = value_{IntQm.n} * 2^{zeros_{leading} - 1} * 2^{-(m+n)}$$\n",
    "\n",
    "So\n",
    "\n",
    "$$\\frac{1}{value_{FloatCano}} = f(value_{shifted}) * 2^{(zeros_{leading} - 1) - m}$$\n",
    "\n",
    "and $$value_{shifted}$$ can be interpreted as the canonicalize representation for Q0.m+n format.\n",
    "\n",
    "where function f is the newton-ralpson method.\n",
    "\n",
    "---\n",
    "\n",
    "Another view of this problem, when we transform Qm.n into Q0.m+n format, we need to shift left by m bits, but we don't shift that just yet, we can shift leading_zeros - 1, so we will still need to shift left by m + 1 - leading_zeros bits.\n",
    "\n",
    "---\n",
    "\n",
    "In reality, since for newton-ralpson method we need to represent 48/17, which will require Q2.m+n-2 representation, note, from Q0.m+n to Q2.m+n-2 is just to shift right by two bits or shift left by -2 bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clz(value):\n",
    "  assert value >= 0\n",
    "  if value.dtype == np.int32:\n",
    "    total_bits = 32\n",
    "  elif vlaue.dtype == np.int16:\n",
    "    total_bits = 16\n",
    "  else:\n",
    "    assert False\n",
    "    \n",
    "  return total_bits - (len(bin(value)) - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedPoint:\n",
    "  def __init__(self, integer, fractional, datatype=np.int32, scale=None, zero_point=None):\n",
    "    # datatype is either np.int16 or np.int32.\n",
    "    self.integer = integer\n",
    "    self.fractional = fractional\n",
    "    self.datatype = datatype\n",
    "    self.value = None\n",
    "    self.scale = scale\n",
    "    self.zero_point = zero_point\n",
    "    if self.scale:\n",
    "      self.multiplier = self.from_float(self.scale)\n",
    "    \n",
    "  def set_raw_value(self, value):\n",
    "    self.value = value\n",
    "    \n",
    "  def get_raw_value(self):\n",
    "    return self.value\n",
    "    \n",
    "  def to_float(self):\n",
    "    return self.value * (2 ** (-self.fractional))\n",
    "\n",
    "  def from_float(self, value):\n",
    "    temp = value * (2 ** self.fractional)\n",
    "    if self.datatype == np.int32:\n",
    "      max_value = 2 ** 31 - 1\n",
    "      min_value = - 2 ** 31\n",
    "    elif self.datatype == np.int16:\n",
    "      max_value = 2 ** 15 - 1\n",
    "      min_value = -2 ** 15\n",
    "    else:\n",
    "      # Should not reached\n",
    "      assert False\n",
    "    \n",
    "    temp = max(min(temp, max_value), min_value)\n",
    "    return self.datatype(temp)\n",
    "    \n",
    "  def from_q_tensor(self, value):\n",
    "    # This may result in overflow\n",
    "    return (value - self.zero_point) * self.multiplier\n",
    "\n",
    "  # currently we only support same type arithmetics.\n",
    "  def check(self, another):\n",
    "    assert self.integer == another.integer\n",
    "    assert self.fractional == another.fractional\n",
    "    assert self.datatype == another.datatype\n",
    "    \n",
    "  def add(self, another):\n",
    "    self.check(another)\n",
    "    result = FixedPoint(self.integer, self.fractional, self.datatype, self.scale, self.zero_point)\n",
    "    # We need to be careful about overflow.\n",
    "    result.set_raw_value(self.get_raw_value() + another.get_raw_value())\n",
    "    return result\n",
    "\n",
    "  def sub(self, another):\n",
    "    self.check(another)\n",
    "    result = FixedPoint(self.integer, self.fractional, self.datatype, self.scale, self.zero_point)\n",
    "    # We need to be careful about overflow.\n",
    "    result.set_raw_value(self.get_raw_value() - another.get_raw_value())\n",
    "    return result\n",
    "\n",
    "  def mul(self, another):\n",
    "    self.check(another)\n",
    "    result = FixedPoint(self.integer, self.fractional, self.datatype, self.scale, self.zero_point)\n",
    "    # We need to be careful about overflow.\n",
    "    temp = np.int64(self.get_raw_value()) * np.int64(another.get_raw_value())\n",
    "    temp = rounding_divide_by_POT(temp, self.fractional)                        \n",
    "    result.set_raw_value(temp)\n",
    "    return result\n",
    "\n",
    "  def neg(self):\n",
    "    result = FixedPoint(self.integer, self.fractional, self.datatype, self.scale, self.zero_point)\n",
    "    assert self.get_raw_value() != None\n",
    "    result.set_raw_value(-self.get_raw_value())\n",
    "    return result\n",
    "\n",
    "  # this only handles cannonical format of Q2.x.\n",
    "  def _reciprocal_for_cano(self, iteration=2):\n",
    "    a = FixedPoint(2, 29, np.int32)\n",
    "    a.set_raw_value(a.from_float(48.0 / 17.0))\n",
    "    b = FixedPoint(2, 29, np.int32)\n",
    "    b.set_raw_value(a.from_float(32.0 / 17.0))\n",
    "    one = FixedPoint(2, 29, np.int32)\n",
    "    one.set_raw_value(one.from_float(1.0))\n",
    "    result = a.sub(self.mul(b))\n",
    "    for i in range(iteration):\n",
    "      temp = one.sub(self.mul(result))\n",
    "      temp = temp.mul(result)\n",
    "      result = result.add(temp)\n",
    "    return result\n",
    "\n",
    "  def reciprocal(self, iteration=2):\n",
    "    # We should also check hte raw value should not be 0.\n",
    "    if self.get_raw_value() < 0:\n",
    "      return self.neg().reciprocal().neg()\n",
    "\n",
    "    leading_zeros = clz(self.get_raw_value())\n",
    "    # We need to shift left leading_zeros - 1 bits so the raw value is in the canonical format for Q0.n.\n",
    "    # We also need to shift right by 2 bits so the raw_value is in the Q2.n case.\n",
    "    shift_left_bits = leading_zeros - 1 - 2\n",
    "    raw_value = self.get_raw_value() * (2 ** shift_left_bits)\n",
    "    cano = FixedPoint(2, 29, self.datatype)\n",
    "    cano.set_raw_value(raw_value)\n",
    "    # Note the return is actually in Q2.n format.\n",
    "    # we still need to shift left by leading_zeros bits -1 - m.\n",
    "    cano_reci = cano._reciprocal_for_cano(iteration)\n",
    "    final_shift_left_bits = leading_zeros - 1 - self.integer\n",
    "    final_raw_value = cano_reci.get_raw_value()\n",
    "    # Since we're using Q2.n, it's possible we run into shift left < -2 scenario,\n",
    "    # in that sense, we need to shift right the value.\n",
    "    if final_shift_left_bits < -2:\n",
    "      value_shift_right_bits = -2 - final_shift_left_bits\n",
    "      final_raw_value = rounding_divide_by_POT(final_raw_value, value_shift_right_bits)\n",
    "      final_shift_left_bits = -2\n",
    "    result = FixedPoint(cano_reci.integer + final_shift_left_bits,\n",
    "                        cano_reci.fractional - final_shift_left_bits,\n",
    "                        cano_reci.datatype)\n",
    "    result.set_raw_value(final_raw_value)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Diff is 5.492057929116291e-06\n",
      "Avg Diff is 5.492057929116291e-06\n",
      "Max Diff is 2.3948337191770364e-05\n",
      "Max Diff is 2.3948337191770364e-05\n"
     ]
    }
   ],
   "source": [
    "# Let's verify reciprocal for the canonical format first.\n",
    "cano_test_data = np.arange(0.5, 0.99, 0.001)\n",
    "\n",
    "cano_expect_result = []\n",
    "cano_true_result = []\n",
    "for item in cano_test_data:\n",
    "  expect_value = 1.0 / item\n",
    "  test = FixedPoint(2, 29, np.int32)\n",
    "  test.set_raw_value(test.from_float(item))\n",
    "  result = test.reciprocal().to_float()\n",
    "  cano_expect_result.append(expect_value)\n",
    "  cano_true_result.append(result)\n",
    "    \n",
    "cano_expect_result = np.array(cano_expect_result)\n",
    "cano_true_result = np.array(cano_true_result)\n",
    "\n",
    "print(\"Avg Diff is %s\" % (diff(cano_expect_result, cano_true_result)))\n",
    "print(\"Avg Diff is %s\" % (diff(cano_expect_result, cano_true_result)))\n",
    "print(\"Max Diff is %s\" % (max_diff(cano_expect_result, cano_true_result)))\n",
    "print(\"Max Diff is %s\" % (max_diff(cano_expect_result, cano_true_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Diff is 3.077765745413778e-06\n",
      "Max Diff is 8.51779436708e-05\n"
     ]
    }
   ],
   "source": [
    "# Let's also verify reciprocal for a wider range (including negative values.)\n",
    "test_data = np.arange(-10.5, 10.5, 0.2)\n",
    "\n",
    "expect_result = []\n",
    "true_result = []\n",
    "for item in test_data:\n",
    "  expect_value = 1.0 / item\n",
    "  test = FixedPoint(4, 27, np.int32)\n",
    "  test.set_raw_value(test.from_float(item))\n",
    "  test = test.reciprocal()\n",
    "  result = test.to_float()\n",
    "  expect_result.append(expect_value)\n",
    "  true_result.append(result)\n",
    "\n",
    "expect_result = np.array(expect_result)\n",
    "true_result = np.array(true_result)\n",
    "\n",
    "print(\"Avg Diff is %s\" % (diff(expect_result, true_result)))\n",
    "print(\"Max Diff is %s\" % (max_diff(expect_result, true_result)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to my college tianlin, I decided to expand this codelab to cover sin. (well, if you know how to handle sin, cos should be just trivial. :) )\n",
    "\n",
    "---\n",
    "### Sin\n",
    "\n",
    "For reference, please see details [here](https://en.wikipedia.org/wiki/Small-angle_approximation).\n",
    "\n",
    "$$\\sin \\theta = \\sum^{\\infty}_{n=0} \\frac{(-1)^n}{(2n+1)!} \\theta^{2n+1}$$\n",
    "\n",
    "And I found we can get good approximation with a few expansions (6~7), See the followig code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Diff is 3.23777951746771e-05\n",
      "Max Diff is 0.0004422558761439342\n"
     ]
    }
   ],
   "source": [
    "def sin(radian, expansion=6):\n",
    "  sign = 1\n",
    "  divi = 1\n",
    "  result = radian\n",
    "  theta = radian\n",
    "  for i in range(1, expansion):\n",
    "    divi *= (2 * i) * (2 * i + 1)\n",
    "    theta *= radian * radian\n",
    "    sign *= -1\n",
    "    result += sign * theta / divi\n",
    "  return result\n",
    "\n",
    "test_data = np.arange(0, math.pi, 0.01)\n",
    "\n",
    "expect_result = np.sin(test_data)\n",
    "\n",
    "true_result = []\n",
    "\n",
    "for item in test_data:\n",
    "  true_result.append(sin(item))\n",
    "\n",
    "true_result = np.array(true_result)\n",
    "\n",
    "print(\"Avg Diff is %s\" % (diff(expect_result, true_result)))\n",
    "print(\"Max Diff is %s\" % (max_diff(expect_result, true_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg Diff is 0.0007714679334449271\n",
      "Max Diff is 0.014670956791459133\n"
     ]
    }
   ],
   "source": [
    "# Let's implement sin with fixed point math!\n",
    "\n",
    "# Let's just assume radian is in Q2.29.\n",
    "# Also, Let's just assume all the value are within [-pi/2, pi/2]\n",
    "def sin_fixed_point(radian):\n",
    "  multiplier_1 = FixedPoint(2, 29, np.int32)\n",
    "  multiplier_2 = FixedPoint(2, 29, np.int32)\n",
    "  multiplier_3 = FixedPoint(2, 29, np.int32)\n",
    "  multiplier_4 = FixedPoint(2, 29, np.int32)\n",
    "  multiplier_5 = FixedPoint(2, 29, np.int32)\n",
    "\n",
    "  multiplier_1.set_raw_value(-89478485)\n",
    "  multiplier_2.set_raw_value(4473924)\n",
    "  multiplier_3.set_raw_value(-106522)\n",
    "  multiplier_4.set_raw_value(1479)\n",
    "  multiplier_5.set_raw_value(-13)\n",
    "  \n",
    "  result = radian\n",
    "  radian_square = radian.mul(radian)\n",
    "  \n",
    "  # We're trying to avoid the overflow issue by afford some computation cost.\n",
    "  multiplier_1 = multiplier_1.mul(radian_square)\n",
    "  result = result.add(radian.mul(multiplier_1))\n",
    "  multiplier_2 = multiplier_2.mul(radian_square).mul(radian_square)\n",
    "  result = result.add(radian.mul(multiplier_2))\n",
    "  multiplier_3 = multiplier_3.mul(radian_square).mul(radian_square).mul(radian_square)\n",
    "  result = result.add(radian.mul(multiplier_3))\n",
    "  multiplier_4 = multiplier_4.mul(radian_square).mul(radian_square).mul(radian_square).mul(radian_square)\n",
    "  result = result.add(radian.mul(multiplier_4))\n",
    "  multiplier_5 = multiplier_4.mul(radian_square).mul(radian_square).mul(radian_square).mul(radian_square).mul(radian_square)\n",
    "  result = result.add(radian.mul(multiplier_5))\n",
    "  return result\n",
    "\n",
    "fixed_point_test_data = np.arange(-math.pi / 2.0, math.pi / 2.0, 0.01)\n",
    "\n",
    "fixed_point_expect_result = np.sin(fixed_point_test_data)\n",
    "\n",
    "fixed_point_true_result = []\n",
    "\n",
    "for item in fixed_point_test_data:\n",
    "  test = FixedPoint(2, 29, np.int32)\n",
    "  test.set_raw_value(test.from_float(item))\n",
    "  result = sin_fixed_point(test)\n",
    "  fixed_point_true_result.append(result.to_float())\n",
    "\n",
    "fixed_point_true_result = np.array(fixed_point_true_result)\n",
    "\n",
    "print(\"Avg Diff is %s\" % (diff(fixed_point_expect_result, fixed_point_true_result)))\n",
    "print(\"Max Diff is %s\" % (max_diff(fixed_point_expect_result, fixed_point_true_result)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quantization computation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIs4wgVEul7R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGBpdfFivVE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tensor:\n",
        "  def __init__(self, value, scale, zero_point):\n",
        "    self.value = value\n",
        "    self.scale = scale\n",
        "    self.zero_point = zero_point\n",
        "    # There're other variants need to consider:\n",
        "    # Datatype? Bits? Per-axis?"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5U_Zz8QzTGwz",
        "colab_type": "text"
      },
      "source": [
        "# Section: Quantized Mul\n",
        "\n",
        "---\n",
        "## To Begin\n",
        "\n",
        "Let's revisit our quantization schema:\n",
        "\n",
        "$$lhs_{float} = (lhs_{quant} - lhs_{zp}) * lhs_s$$\n",
        "$$rhs_{float} = (rhs_{quant} - rhs_{zp}) * rhs_s$$\n",
        "$$output_{float} = (output_{quant} - output_{zp}) * output_s$$\n",
        "\n",
        "---\n",
        "Bring those to our mul implementation:\n",
        "\n",
        "$$output_{float} = lhs_{float} * rhs_{float}$$\n",
        "    =>\n",
        "$$(output_{quant} - output_{zp}) * output_s = (lhs_{quant} - lhs_{zp}) * lhs_s * (rhs_{quant} - rhs_{zp}) * rhs_s$$\n",
        "\n",
        "=>\n",
        "$$output_{quant} - output_{zp} = (lhs_{quant} - lhs_{zp}) * (rhs_{quant} - rhs_{zp}) * (\\frac{lhs_s * rhs_s}{output_s})$$\n",
        "\n",
        "\n",
        "Let $$real_s = \\frac{lhs_s * rhs_s}{output_s}$$ since we can easily fold this one.\n",
        "\n",
        "---\n",
        "Since our goal is to compute output_q, we will have the following equation:\n",
        "\n",
        "\n",
        "$$output_{quant} = (lhs_{quant} - lhs_{zp}) * (rhs_{quant} - rhs_{zp}) * real_s + output_{zp}$$\n",
        "\n",
        "\n",
        "So far so good, but just a second, what's the promise of **integer-only**?\n",
        "Isn't $$real_s$$ a float number? \n",
        "\n",
        "---\n",
        "\n",
        "## Integer-only \n",
        "\n",
        "Let's slightly change the representation:\n",
        "\n",
        "$$real_s = real_{can} * 2^{shift}$$.\n",
        "\n",
        "$$real_{can}$$ is a canonical representation of the float value, ranges between [0.5, 1), please note our scale is always a positive value, while *shift* is essentially the shift (a left shift if positive, a right shift if negative).\n",
        "\n",
        "In fact, ```std::frexp``` will help us with the job, see the documentation [here](https://en.cppreference.com/w/cpp/numeric/math/frexp).\n",
        "\n",
        "Let's just apply one more trick:\n",
        "\n",
        "$$real_s = \\frac{real_{can} * 2^{31} * 2^{shift}}{2^{31}} $$\n",
        "\n",
        "\n",
        "and $$multiplier = real_{can} * 2^{31}$$\n",
        "\n",
        "is within the range of int32 representation, rember the canonicacal representation is within [0.5, 1)? so that value is within [2^30, 2^31 - 1], and we\n",
        "can easily cast that value to int32 with very minimum accuracy lost.\n",
        "\n",
        "---\n",
        "## Put it together\n",
        "Now we know:\n",
        "\n",
        "$$output_{quant} = \\frac{temp* multiplier}{2^{31}} * 2^{shift} + output_{zp}$$\n",
        "\n",
        "where $$temp = (lhs_{quant} - lhs_{zp}) * (rhs_{quant} - rhs_{zp})$$\n",
        "\n",
        "Here's the beautilful part:\n",
        "\n",
        "$$(*) = \\frac{temp* multiplier}{2^{31}}$$ is actually pretty *cheap* for the hardware (ARM):\n",
        "\n",
        "ARM actually has a very verbose name for that: \"Signed saturating Rounding Doubling Multiply returning High half.\" The hardware instruction is acutally just [\"VQRDMULH\"](http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dui0473j/dom1361289977828.html).\n",
        "\n",
        "What it does is multiplying the two values then returning the signifiant half (also, rounding).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQXnG6NbTwId",
        "colab_type": "text"
      },
      "source": [
        "### Special Note\n",
        "In previous section, we talked about using int32 for multiplier & temp data, it's also possible to use int16 (but we need to be careful about overflow issue)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xui0pwuurBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Util functions.\n",
        "def saturate_rounding_doubling_multiply(value1, value2, datatype):\n",
        "  # rounding is essentially rounded_value = floor(value + 0.5)\n",
        "  if datatype == np.int16:\n",
        "    half = 2 ** 14\n",
        "    base = 2 ** 15\n",
        "    min_value = -(2 ** 15)\n",
        "    max_value = 2 ** 15 - 1\n",
        "  elif datatype == np.int32:\n",
        "    half = 2 ** 30\n",
        "    base = 2 ** 31\n",
        "    min_value = - (2 ** 31)\n",
        "    max_value = 2 ** 31 - 1\n",
        "  else:\n",
        "    assert False  # Not reached.\n",
        "  temp = np.int64(value1) * np.int64(value2)\n",
        "  if temp < 0:\n",
        "    half *= -1\n",
        "  temp += half\n",
        "  temp /= base\n",
        "  return min(max(temp, min_value), max_value)\n",
        "\n",
        "\n",
        "def rounding_divide_by_POT(value, exponent):\n",
        "  assert exponent >= 1\n",
        "  half = 2 ** (exponent - 1)\n",
        "  if value < 0:\n",
        "    half *= -1\n",
        "  return (value + half) / (2 ** exponent)\n",
        "\n",
        "\n",
        "def apply_shift(value, exponent):\n",
        "  if exponent >= 0:\n",
        "    # Left shift\n",
        "    value *= (2 ** exponent)\n",
        "  else:\n",
        "    # Right shift\n",
        "    value = rounding_divide_by_POT(value, -exponent)\n",
        "  return value\n",
        "\n",
        "def dequant(tensor):\n",
        "  return (np.array(tensor.value, dtype=np.int32) - tensor.zero_point) * tensor.scale\n",
        "\n",
        "\n",
        "def diff(value1, value2):\n",
        "  diff = np.abs(value1 - value2)\n",
        "  return np.sum(diff) / (value1.size * 1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZnh9u2jYLfi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data prepare.\n",
        "def populate_data(shape, min_value, max_value):\n",
        "  value_range = max_value - min_value\n",
        "  float_value = np.random.random_sample(shape) * value_range + min_value\n",
        "  scale = (value_range) / 256\n",
        "  zero_point = -int((max_value + min_value) / (2.0 * scale))\n",
        "  quant_value = np.array(float_value / float(scale) + zero_point, dtype=np.int8)\n",
        "  q_tensor = Tensor(quant_value, scale, zero_point)\n",
        "  return float_value, q_tensor\n",
        "\n",
        "lhs_float, lhs_q_tensor = populate_data((4, 4, 4), -4.0, 5.0)\n",
        "rhs_float, rhs_q_tensor = populate_data((4, 4, 4), -1.5, 0.9)\n",
        "\n",
        "# ouput ranges (-7.5, 6.0).\n",
        "# Let's just assume the output has the following:\n",
        "out_scale = (6.0 + 7.5) / 256.0\n",
        "out_zp = -(6.0 - 7.5) / (2.0 * out_scale)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc_H3VnXHuY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def multiply(tensor1, tensor2, output_tensor, datatype=np.int32):\n",
        "  real_scale = tensor1.scale * tensor2.scale / output_tensor.scale\n",
        "  multipler_float, shift = np.frexp(real_scale)\n",
        "  if datatype == np.int32:\n",
        "    multiplier_shift = 31\n",
        "  elif datatype == np.int16:\n",
        "    multiplier_shift = 15\n",
        "  else:\n",
        "    assert False\n",
        "  multiplier = datatype(multipler_float * (2 ** multiplier_shift))\n",
        "\n",
        "  for i in range(tensor1.value.size):\n",
        "    lhs_value = datatype(tensor1.value.ravel()[i])\n",
        "    lhs_value -= tensor1.zero_point\n",
        "    rhs_value = datatype(tensor2.value.ravel()[i])\n",
        "    rhs_value -= tensor2.zero_point\n",
        "    # We need to be careful about the overflow issue when the datatype is int16\n",
        "    temp = datatype(lhs_value * rhs_value)\n",
        "    product = saturate_rounding_doubling_multiply(temp, multiplier, datatype)\n",
        "    output = apply_shift(product, shift)\n",
        "    output += output_tensor.zero_point\n",
        "    output = np.int8(min(max(output, -128), 127))\n",
        "    output_tensor.value.ravel()[i] = output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZYEEIWJABo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f503c4d1-e310-4f9d-b26f-45366ad64734"
      },
      "source": [
        "# First, let's make sure both the inputs are close to our range.\n",
        "np.allclose(lhs_float, dequant(lhs_q_tensor), atol=5e-2)\n",
        "np.allclose(rhs_float, dequant(rhs_q_tensor), atol=5e-2)\n",
        "\n",
        "# Let's check the average deviation as well: avg(abs(a - b))\n",
        "print(\"Avg deviation between lhs float and quantized representation is %.3f\" % diff(lhs_float, dequant(lhs_q_tensor)))\n",
        "print(\"Avg deviation between rhs float and quantized representation is %.3f\" % diff(rhs_float, dequant(rhs_q_tensor)))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Avg deviation between lhs float and quantized representation is 0.017\n",
            "Avg deviation between rhs float and quantized representation is 0.005\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OM9TWOsg_1zv",
        "colab_type": "code",
        "outputId": "4f561937-0e92-498e-d085-791143217a6d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# True result\n",
        "expect_result = lhs_float * rhs_float\n",
        "\n",
        "\n",
        "# Let's see how the quantized kernel works out:\n",
        "out_tensor = Tensor(np.zeros(lhs_float.shape), out_scale, out_zp)\n",
        "multiply(lhs_q_tensor, rhs_q_tensor, out_tensor, np.int32)\n",
        "\n",
        "# Let's make sure it's within 0.2 range\n",
        "result = np.allclose(expect_result, dequant(out_tensor), atol=2e-1)\n",
        "print(\"With in 0.2 range \", result)\n",
        "\n",
        "# Also, let's see the average deviation:\n",
        "print(\"Avg deviation between output float and quantized representation is %.3f\" % diff(expect_result, dequant(out_tensor)))\n",
        "\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With in 0.2 range  True\n",
            "Avg deviation between output float and quantized representation is 0.035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBjlE5xThDaP",
        "colab_type": "text"
      },
      "source": [
        "## What's Next?\n",
        "*   Conv? MatMul?\n",
        "*   Fixed point?\n",
        "*   Activations?"
      ]
    }
  ]
}